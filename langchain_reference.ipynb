{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Setup",
   "id": "c86f3d83ad4a715a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T15:40:41.309699Z",
     "start_time": "2024-08-09T15:40:37.443285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!python -m pip -q install --upgrade pip\n",
    "!pip install -e ."
   ],
   "id": "dc957a611930f73c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/pprados/workspace.bda/langchain-references\r\n",
      "  Installing build dependencies ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Checking if build backend supports build_editable ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Getting requirements to build editable ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Preparing editable metadata (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25hBuilding wheels for collected packages: langchain_references\r\n",
      "  Building editable for langchain_references (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for langchain_references: filename=langchain_references-0.0.0-0.editable-py3-none-any.whl size=7019 sha256=736a538956f99d092206fdf1a5888fcaed6c25e3a6f0c7a1e980b4d603b95949\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-k98e9tq2/wheels/a4/32/87/e1597a08c9777b23e5130be598110a6cbb924fc8978b83f36d\r\n",
      "Successfully built langchain_references\r\n",
      "Installing collected packages: langchain_references\r\n",
      "  Attempting uninstall: langchain_references\r\n",
      "    Found existing installation: langchain_references 0.0.0\r\n",
      "    Not uninstalling langchain-references at /home/pprados/workspace.bda/langchain-references, outside environment /home/pprados/workspace.bda/langchain-rag/.venv\r\n",
      "    Can't uninstall 'langchain_references'. No files were found to uninstall.\r\n",
      "Successfully installed langchain_references-0.0.0\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T15:40:46.608582Z",
     "start_time": "2024-08-09T15:40:41.311068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Document loading, retrieval methods and text splitting\n",
    "%pip install -qU langchain-references\n",
    "%pip install -qU langchain-community\n",
    "%pip install -qU langchain-text-splitters\n",
    "\n",
    "# Local vector store via Chroma\n",
    "%pip install -qU langchain_chroma\n",
    "\n",
    "# Local inference and embeddings via Ollama\n",
    "%pip install -qU langchain_ollama"
   ],
   "id": "aa3cb4127a38ba2c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T15:40:46.967955Z",
     "start_time": "2024-08-09T15:40:46.614399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import langchain_references\n",
    "\n",
    "langchain_references.__version__"
   ],
   "id": "eb8191ca50131426",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.0.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Document loading, retrieval methods and text splitting\n",
    "Load documents from the web and split them into smaller chunks for processing."
   ],
   "id": "83768f43742ddfb4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T15:40:47.189905Z",
     "start_time": "2024-08-09T15:40:46.969737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ[\"USER_AGENT\"] = \"langhchain-references\"\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "data = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(data)"
   ],
   "id": "4ead84bd97afdfdf",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Choose a vectorstore to use for similarity search",
   "id": "7dec526917833040"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T15:41:09.217685Z",
     "start_time": "2024-08-09T15:40:47.190955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "local_embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=local_embeddings)"
   ],
   "id": "5f9d7467fe848c28",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Choose a model to use for question answering",
   "id": "bb9b452742f5a108"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T15:41:09.222751Z",
     "start_time": "2024-08-09T15:41:09.218683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "model = ChatOllama(\n",
    "    model=\"llama3\",\n",
    ")"
   ],
   "id": "cfcb9989a0c1fdd9",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    ")"
   ],
   "id": "53a0a62f6b431da6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Combine the documents into a single string, but with a uniq small numeric id.",
   "id": "1d490499f3dd0f2a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T15:41:09.227088Z",
     "start_time": "2024-08-09T15:41:09.223673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def format_docs(docs):\n",
    "    # return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    return \"\\n\".join(\n",
    "        # Add a document id so that LLM can reference it \n",
    "        [f\"<document id={i + 1}>\\n{doc.page_content}\\n</document>\\n\" for i, doc in\n",
    "         enumerate(docs)]\n",
    "    )\n"
   ],
   "id": "e1ab24ab1ce6756a",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Manage references with langchain-reference",
   "id": "66fa627b954ca485"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create a prompt with {format_references} and {context} placeholders.",
   "id": "40dbd4cd88b69484"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T15:41:09.230154Z",
     "start_time": "2024-08-09T15:41:09.227736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "RAG_TEMPLATE = \"\"\"\n",
    "You are an assistant for question-answering tasks. Use the following pieces of retrieved documents to answer the question. \n",
    "If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "{format_references}\n",
    "  \n",
    "<documents>\n",
    "{documents}\n",
    "</documents>\n",
    "\n",
    "Answer the following question:\n",
    "\n",
    "{question}\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)"
   ],
   "id": "17de643f3bab60f0",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create a context with documents and format_references.",
   "id": "ae2da97e71ccc295"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T15:41:09.233156Z",
     "start_time": "2024-08-09T15:41:09.230896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_references import *\n",
    "\n",
    "context = RunnablePassthrough.assign(\n",
    "    documents=lambda input: format_docs(input[\"documents\"]),\n",
    "    format_references=lambda _: FORMAT_REFERENCES,\n",
    ")"
   ],
   "id": "6bb1bd80c65a3fe8",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create a chain with the context, rag_prompt and model, and encapulate it with `manage_references()`.",
   "id": "8cb0d6f292c89f32"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T15:41:09.396928Z",
     "start_time": "2024-08-09T15:41:09.234899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = manage_references(\n",
    "    context\n",
    "    | rag_prompt\n",
    "    | model,\n",
    ") | StrOutputParser()\n",
    "\n",
    "question = \"What are the approaches to Task Decomposition?\"\n",
    "\n",
    "docs = vectorstore.similarity_search(question)"
   ],
   "id": "b1989acf92d988d9",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Invoke the chain with the documents and question.",
   "id": "f018a406e58e2768"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T15:41:23.364220Z",
     "start_time": "2024-08-09T15:41:09.397904Z"
    }
   },
   "cell_type": "code",
   "source": "print(chain.invoke({\"documents\": docs, \"question\": question}))",
   "id": "5f5d2df72ae94ae8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to documents ^[1](https://lilianweng.github.io/posts/2023-06-23-agent/)^ and ^[1](https://lilianweng.github.io/posts/2023-06-23-agent/)^ there are three approaches to task decomposition: using simple prompting like \"Steps for XYZ.\\n1.\", using task-specific instructions, and with human inputs. These methods help break down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
      "\n",
      "- **1** [LLM Powered Autonomous Agents | Lil'Log](https://lilianweng.github.io/posts/2023-06-23-agent/)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T15:41:23.366829Z",
     "start_time": "2024-08-09T15:41:23.365273Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5f9f80470fab785b",
   "outputs": [],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-references",
   "language": "python",
   "name": "langchain-references"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
